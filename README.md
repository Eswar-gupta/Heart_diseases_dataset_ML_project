---

## ğŸ“Š Dataset
- This dataset is obtained from Kaggle: [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

## ğŸ§  Context
- The dataset contains 11 features that can be used to predict the presence of heart disease.  
- A machine learning model was trained to assist with diagnosing this disease.

## ğŸ“ˆ Results
- Random Forest has highest accuracy

| ğŸ§ª Model          | ğŸ‹ï¸ Train Accuracy | ğŸ§¾ Test Accuracy |
|-------------------|-------------------|------------------|
| ğŸ”¹ KNN             | 88.5%             | 87.2%            |
| ğŸŒ³ Decision Tree   | 85.42%            | 84.24%           |
| ğŸŒ² Random Forest   | 92.92%            | 89.13%           |
| âš¡ XGBoost          | 96.73%            | 85.33%           |
| ğŸ§  Neural Network  | 87.46%            | 85.3%            |

## ğŸ› ï¸ Work Done
- Built on Andrew Ngâ€™s ML Specialization course, which compares Decision Trees, Random Forest, and XGBoost.  
- Extended the comparison by adding Neural Networks and KNN and tried to outperfrome Random Forest.  
- Notably, **KNN** achieved the **second-highest test accuracy**, highlighting the power of simple, well-preprocessed models.

> #### âš ï¸ Note  
> All models performed similarly (only a **3â€“4%** test accuracy spread). The reasons below reflect my interpretation of each model's strengths in this context.

### ğŸ” Reasons for Random Forest outperforming others:
1. **âš¡ XGBoost**  
   - Highest training accuracy but lower test accuracy â†’ suggests **overfitting** on ~700 samples. As data is small we no need this big model
2. **ğŸŒ³ Decision Tree**  
   - Single-tree models often **overfit** or **underfit**, compared to ensemble methods like XGBoost or Random forest.  
3. **ğŸ”¹ KNN**  
   - Achieved **87.2%** test accuracy (2nd best), indicating a well-scaled feature space favorable for proximity-based learning.  
4. **ğŸ§  Neural Networks**  
   - Typically need **larger datasets**; with only ~700 samples, they risk **overfitting** or **underfitting** despite tuning.

## ğŸ§¾ Attribute Information
- **ğŸ§“ Age**: Age of the patient [years]  
- **ğŸš» Sex**: Sex of the patient [M: Male, F: Female]  
- **â¤ï¸ ChestPainType**: Chest pain type [TA, ATA, NAP, ASY]  
- **ğŸ©º RestingBP**: Resting blood pressure [mm Hg]  
- **ğŸ§ª Cholesterol**: Serum cholesterol [mm/dl]  
- **ğŸ¬ FastingBS**: Fasting blood sugar [1 if > 120 mg/dl, else 0]  
- **ğŸ“‰ RestingECG**: Resting ECG results [Normal, ST, LVH]  
- **ğŸƒ MaxHR**: Maximum heart rate achieved [60â€“202]  
- **ğŸ’” ExerciseAngina**: Exercise-induced angina [Y: Yes, N: No]  
- **ğŸ“‰ Oldpeak**: ST depression induced by exercise  
- **ğŸ“ˆ ST_Slope**: Slope of peak exercise ST segment [Up, Flat, Down]  
- **ğŸ©º HeartDisease**: Target variable [1: Heart disease, 0: Normal]  
